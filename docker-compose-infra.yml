# ============================================
# 基础设施服务 - Docker Compose 配置
# 包含：MySQL、Redis、Qdrant、TEI、vLLM
# 使用方式：
#   docker-compose -f docker-compose.infra.yml up -d
#   docker-compose -f docker-compose.infra.yml --profile ai up -d  # 包含 AI 服务
# ============================================

services:
  # MySQL 数据库
  mysql:
    image: mysql:${MYSQL_VERSION:-8.0}
    container_name: ${CONTAINER_PREFIX:-lm}-mysql
    restart: always
    ports:
      - "${MYSQL_PORT:-3307}:3306"
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD:-root123}
      MYSQL_DATABASE: ${MYSQL_DATABASE:-lumeidb}
      MYSQL_USER: ${MYSQL_USER:-lumei}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD:-lumei123}
      TZ: ${MYSQL_TIMEZONE:-Asia/Shanghai}
    volumes:
      - ${DEPLOY_DIR:-./deploy}/mysql/data:/var/lib/mysql
      - ${DEPLOY_DIR:-./deploy}/mysql/config/custom.cnf:/etc/mysql/conf.d/custom.cnf:ro
    networks:
      - lm-network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD:-root123}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Redis 缓存
  redis:
    image: redis:${REDIS_VERSION:-8.0-alpine}
    container_name: ${CONTAINER_PREFIX:-lm}-redis
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6380}:6379"
    command: redis-server --requirepass ${REDIS_PASSWORD:-redis123456}
    volumes:
      - ${DEPLOY_DIR:-./deploy}/redis/data:/data
    networks:
      - lm-network
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-redis123456}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Qdrant 向量数据库
  qdrant:
    image: qdrant/qdrant:${QDRANT_VERSION:-v1.12.1}
    container_name: ${CONTAINER_PREFIX:-lm}-qdrant
    restart: unless-stopped
    ports:
      - "${QDRANT_HTTP_PORT:-6333}:6333"
      - "${QDRANT_GRPC_PORT:-6334}:6334"
    volumes:
      - ${DEPLOY_DIR:-./deploy}/qdrant/storage:/qdrant/storage
    networks:
      - lm-network

  # TEI 文本嵌入服务（可选，需要 GPU）
  tei:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-${TEI_VERSION:-1.6.0}
    container_name: ${CONTAINER_PREFIX:-lm}-tei
    restart: unless-stopped
    ports:
      - "${TEI_PORT:-8081}:80"
    environment:
      - MODEL_ID=BAAI/bge-m3
    volumes:
      - ${DEPLOY_DIR:-./deploy}/tei/cache:/data
    networks:
      - lm-network
    profiles:
      - ai  # 使用 --profile ai 启动

  # vLLM 大模型推理服务（可选，需要 GPU）
  vllm:
    image: vllm/vllm-openai:${VLLM_VERSION:-latest}
    container_name: ${CONTAINER_PREFIX:-lm}-vllm
    restart: unless-stopped
    ports:
      - "${VLLM_PORT:-8082}:8000"
    environment:
      - MODEL_PATH=${VLLM_MODEL_PATH:-Qwen/Qwen2.5-7B-Instruct}
      - GPU_MEMORY_UTILIZATION=${VLLM_GPU_MEMORY_UTILIZATION:-0.7}
      - MAX_MODEL_LEN=${VLLM_MAX_MODEL_LEN:-4096}
    volumes:
      - ${DEPLOY_DIR:-./deploy}/vllm/models:/models
    networks:
      - lm-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - ai  # 使用 --profile ai 启动

networks:
  lm-network:
    name: ${NETWORK_NAME:-lm-network}
    driver: bridge
